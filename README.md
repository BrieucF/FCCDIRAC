[]() Getting Started with FCCDIRAC
==========================================

Contents:

-   [FCCDIRAC](#fccdirac)
    -   [Overview](#overview)
	-	[1 - Existing Infrastructure](#infra)
		-	[a - GRID's philosophy](#gridphi)
		-	[b - DIRAC](#dirac)
	-	[2 - FCCDIRAC](#fccdirac)
		-	[a - Objective of this package](#objective)
		-	[b - Workflow](#workflow)
    -   [Prerequisites](#prerequisites)
        -   [1- GRID access](#gridacc)
        -   [2- Setting up ILCDIRAC environment](#diracenv)
    -	[FCCDIRAC Installation](#installation)
    -   [Examples](#examples)
        -   [1- Simple FCC job](#simplefccjob)
        -   [2- Complex FCC Job](#complexfccjob)
    -   [Get Back Results](#results)
        -   [1- Command Line Interface](#cli)
        -   [2- Web Portal](#web)





[]() Overview
-------------



### []() 1 - Existing Infrastructure


### []() a - GRID's philosophy

The amount of data generated by the LHC (Large Hadron Collider) show that it is very unlikely that one scientific 
center may scope in managing data because of computing resources required by such applications.

Indeed, to give you a figure, LHC generated about 50 Petabytes in 2016 and the solution was to distribute data over many centers.
That's the prurpose of the creation of the WLCG (Worldwide LHC Computing Grid) which is a global collaboration of more than 170 computing centres in 42 countries, 
linking up national and international grid infrastructures

In this way, WLCG offers the following advantages :

- replication of data
- access data by everyone from anywhere
- Backups between different sites 


WLCG is the world's largest computing grid and it is based on two main grids which are EGI (the European Grid Infrastructure) in Europe, and OSG (the Open Science Grid) in the US.

Apart from the fact that 10 000 scientists are working on the four main experiments ALICE, ATLAS, CMS and LHCb , authorized users can acces the GRID and run their own job thanks to the 'Middlewares'.


### []() b - DIRAC

DIRAC (Distributed Infrastructure with Remote Agent Control) INTERWARE is a software framework for distributed computing providing a complete solution to people requiring access to
a GRID. 

DIRAC project was initially developed for the LHCb Collaboration and became a general-purpose Grid Middleware.

DIRAC builds a layer between the users and the resources offering a homogeneous interface to an heterogeneous set of computing resources (Middlewares, VMs,laptops,...). 
It is now used by several communities (more than 20 Virtual Organizations e.g. LHCb, Belle etc...).

FCC choose to use DIRAC because of its many benefits (Non-exhaustive list) :

- Workload Management
- Transformations
- Monitoring
- Accounting
- Security (DISET)
- BookKeeping
- Webportal (a Friendly Web interface to monitor your jobs)


### []() 2 - FCCDIRAC

### []() a - Objective of this package

Before using DIRAC, you need to fullfill the prerequistes. The package is a set of python scripts that permit you to submit a job without reading the documentation of DIRAC.
It aims to offer you the more intuitive way to run FCC software on the GRID by hiding the DIRAC machinery as much as possible.

At the end of this tutorial, you will be able from your seat to run a job on a machine located at the other side of the planet without paying attention about WHERE or HOW it works,
all this thanks to the GRID infrastructure and Abstraction layer built by DIRAC.


### []() b - Workflow

![Texte alternatif](https://github.com/sfernana/FCCDIRAC/blob/master/tutorial_images/dag.png "workflow")



[]() Prerequisites
------------------


### []() 1 - GRID access

First, to be able to submit jobs on the GRID, you need to have :
 
- a GRID certificate 


Second, to be able to submit jobs through DIRAC interware, you need :

- to be registered to a VO (Virtual Organization)


Instructions for these 2 primordial steps can be found here :

- [LHCB tutorial](https://twiki.cern.ch/twiki/bin/view/LHCb/FAQ/Certificate)

or here :

- [CLIC tutorial](https://twiki.cern.ch/twiki/bin/view/CLIC/IlcdiracRegistration)


Actually, FCC group does not have its own VO. After Discussion with CLIC people, they authorized some FCC people to join their VO, for which we are very grateful.


So, in the next section, the instuctions of the installation are specifc to ILC VO.


If you encounter some problems with the DIRAC installation, very good tutorials are also available here :


[DIRACGrid tutorial](https://github.com/DIRACGrid/DIRAC/wiki/DIRAC-Tutorials)

or here :

[LCD tutorial](http://lcd-data.web.cern.ch/lcd-data/doc/HeadFirstTalk.pdf)


### []() 2 - Setting up ILCDIRAC environment

IlcDirac is  an  extension  of  the DIRAC framework, it is  built  on  top  of  the  workflow  API  from Dirac. 

ILCDirac offers a set of applications used  in  the  LC  community and there 14  that are  currently  supported  natively by ILCDirac. 
Among  them  are  :

-	SLIC and Mokka (detector  simulation  frameworks  based  on Geant4)
-	Marlin and org.lcsim (reconstruction and analysis frameworks)
-	Monte Carlo generators (Whizard,Pythia) and ROOT


Here are the minimum requirements if you want to continue this tutorial :

-	a computer running Linux  or MacOS X 
-	able to install some software on your computer user space. 
-	a working version of Python (v2.4 minimum)



If you are a CERN user, ILCDIRAC is already installed on AFS, you can follow the instructions here :

[CLIC twiki tutorial](https://twiki.cern.ch/twiki/bin/view/CLIC/IlcdiracEnvironment#Installing_ILCDIRAC)

Indeed, you only have to source a script and configure DIRAC using a proxy and your grid certificate.

If you do not have access to CERN AFS, you can install DIRAC locally.

The following installation is scpecific to ILC VO but it is quite similar to the general procedure.
Installation scripts (e.g. ilcdirac-install.sh) and cfg files (e.g. defaults-ILCDIRAC.cfg) may differ according to your VO.

In order to install ILCDIRAC, you need to install the ILCDIRAC client. 

This client is composed of a set of commands that allow you to manage your jobs as well as your data.

In order to install ILCDIRAC, you need to convert your GRID certificate from p12 format (as you exported it from your browser) to PEM format.
The client already has a tool for that :D (8th line of the bash script below).

It will store your converted certificate to your .globus directory.


Here are the instructions of how to install ILCDIRAC and configure it with your GRID certificate :


```

#install client
mkdir -p $HOME/DIRAC
cd  $HOME/DIRAC
wget http://www.cern.ch/lcd-data/software/ilcdirac-install.sh
chmod +x ilcdirac-install.sh
./ilcdirac-install.sh
source bashrc
dirac-cert-convert.sh /path/to/your_grid_certificate.p12
dirac-proxy-init -x
./scripts/dirac-configure defaults-ILCDIRAC.cfg
dirac-proxy-init
cd ..

```

The file defaults-ILCDIRAC.cfg is specific to ILC and it is a configuration file which help users to configure DIRAC client according to the VO they are affiliated with.

Each VO using DIRAC should have such a file which helps their users to configure DIRAC client quickly.

If you are affiliated with a VO different from ILC, please refer to your VO DIRAC website or contact your VO administrator.
 


[]() FCCDIRAC Installation
--------------------------


```

mkdir -p $HOME/DIRAC/workspace
cd  $HOME/DIRAC/workspace
git clone https://github.com/sfernana/FCCDIRAC.git
cd FCCDIRAC
./fcc_user_submit.py

```




[]() Examples
-------------

Through the script [fcc_user_submit.py](https://github.com/sfernana/FCCDIRAC/blob/master/fcc_user_submit.py), we provide you a complete example of how to run FCC jobs on the grid.

Let's go step by step with 2 examples.

Through the 2 following examples, the user has to consider that there exist FCC jobs that may contain one or more applications.


### []() 1 - Simple FCC Job


In this simple example, we want to run FCC PHYSICS on the GRID.

```

#!/bin/env python

#************************** libraries importation **************************#

#user libraries
#importations of fcc core classes
from fcc_core import *

#standard libraries
import os

        
#1st FCC job
fcc = Job()

#we specify the source we script
#for now the same for each job
fcc.set_sourcing_script(os.path.join(os.getcwd(), "init_fcc.sh"))

#1st application of the 1st FCC job

#---------------FCC PHYSICS---------------------------------#
fcc_physics = Application()


fcc_physics.set_executable('fcc-pythia8-generate')
fcc_physics.set_configuration_file('/cvmfs/fcc.cern.ch/sw/0.7/fcc-physics/0.1/x86_64-slc6-gcc49-opt/share/ee_ZH_Zmumu_Hbb.txt')

#we add the application to the job
fcc.append(fcc_physics)

#finally, we can submit the 1st FCC job containing 2 applications in this case
fcc.submit()


```



### []() 2 - Complex FCC Job


Now, let us complicate things in adding a new application at our job that is the famous FCCSW.


```


#!/bin/env python

#************************** libraries importation **************************#

#user libraries
#importations of fcc core classes
from fcc_core import *

#standard libraries
import os

        
#1st FCC job
fcc = Job()

#we specify the source we script
#for now the same for each job
fcc.set_sourcing_script(os.path.join(os.getcwd(), "init_fcc.sh"))

#1st application of the 1st FCC job

#---------------FCC PHYSICS---------------------------------#
fcc_physics = Application()


fcc_physics.set_executable('fcc-pythia8-generate')
fcc_physics.set_configuration_file('/cvmfs/fcc.cern.ch/sw/0.7/fcc-physics/0.1/x86_64-slc6-gcc49-opt/share/ee_ZH_Zmumu_Hbb.txt')

#we add the application to the job
fcc.append(fcc_physics)




#2nd application of the 1st FCC job

#---------------FCCSW---------------------------------#
fccsw = Application()


fccsw_path = '/build/<YOUR_USERNAME>/FCC/FCCSW'

#we test these 2 configurations succesfully
#conf_file = os.path.join(fccsw_path,'Examples/options/geant_pgun_fullsim.py')
conf_file = os.path.join(fccsw_path,'Examples/options/simple_pythia.py')

#stuff to call gaudirun.py
python = '/cvmfs/lhcb.cern.ch/lib/lcg/releases/LCG_83/Python/2.7.9.p1/x86_64-slc6-gcc49-opt/bin/python2.7'
xenv = '/cvmfs/lhcb.cern.ch/lib/lhcb/LBSCRIPTS/LBSCRIPTS_v8r5p3/LbUtils/cmake/xenv'
arg_xenv  = 'InstallArea/FCCSW.xenv'
exe = 'gaudirun.py'


fccsw.set_executable('exec ' + python + ' ' + xenv + ' ' + arg_xenv + ' ' + exe)
fccsw.set_configuration_file(conf_file)


fccsw.set_fccsw_path(fccsw_path)

#example of how to add 'extra' files or folders
#fccsw.add_paths(['/afs/cern.ch/user/<YOUR_INITIAL>/<YOUR_USERNAME>/foo.bar','/afs/cern.ch/user/<YOUR_INITIAL>/<YOUR_USERNAME>/HelloWorld'])

fcc.append(fccsw)

#finally, we can submit the 1st FCC job containing 2 applications in this case
fcc.submit()

```

In this example, we supposed that FCCSW folder is located at /build/<YOUR_USERNAME>/FCC.
If necessary, change it to make it point to your real FCCSW location.
 

[]() Results
------------

After you called the script [fcc_user_submit.py](https://github.com/sfernana/FCCDIRAC/blob/master/fcc_user_submit.py), you have to confirm the submission to DIRAC and get a display similar to this one :

![Texte alternatif](https://github.com/sfernana/FCCDIRAC/blob/master/tutorial_images/diracsub.png "submission confirmation")


### []() 1 - Command Line Interface


How to check your job status :

	dirac-wms-job-status YOUR_JOB_ID


How to get back the output :

	dirac-wms-job-get-output YOUR_JOB_ID



### []() 3 - Web Portal


Here is the link to monitor ILCDIRAC job on the web. If you are not affiliated with ILC, please refer to your VO DIRAC website or contact your VO administrator.


https://ilcdirac.cern.ch/DIRAC/?view=tabs&theme=Grey&url_state=1|*DIRAC.FileCatalog.classes.FileCatalog:*DIRAC.JobMonitor.classes.JobMonitor:,



On the left side, click on 'Job Monitor' :

![Texte alternatif](https://github.com/sfernana/FCCDIRAC/blob/master/tutorial_images/jobmonitor.png "job monitoring")


On the right side, click on 'refresh' :

![Texte alternatif](https://github.com/sfernana/FCCDIRAC/blob/master/tutorial_images/refresh.png "job status")


Congratulations !!!

You ran FCC softwares on the GRID.

For any questions or any further informations, please contact us at : fcc-experiments-sw-devATSPAMNOTcern.ch
